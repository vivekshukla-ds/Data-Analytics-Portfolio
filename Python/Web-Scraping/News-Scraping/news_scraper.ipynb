{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1ce2cc9e-82ff-4ea0-a24b-7c7422a9ba6c",
   "metadata": {},
   "source": [
    "### Initializing the imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fe1eca19-818a-4dac-85af-dceebd9d1425",
   "metadata": {},
   "outputs": [],
   "source": [
    "import newspaper\n",
    "import feedparser\n",
    "import pandas as pd\n",
    "import os\n",
    "import time\n",
    "import logging\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8451019e-4101-45a4-b9d7-b651eb33a407",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup configuration\n",
    "RSS_FEEDS = [\n",
    "    \"https://feeds.bbci.co.uk/news/rss.xml\"\n",
    "]\n",
    "\n",
    "MAX_ARTICLES_PER_FEED = 30\n",
    "DELAY_BETWEEN_ARTICLES = 0.5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7873b7f8-fa1d-44d3-b4f8-d579ee192b12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PATH SETUP (RELATIVE & PORTFOLIO SAFE)\n",
    "BASE_DIR = os.getcwd()   # Notebook safe\n",
    "OUTPUT_DIR = os.path.join(BASE_DIR, \"outputs\")\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "OUTPUT_FILE = os.path.join(OUTPUT_DIR, \"news_articles.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1396b8b7-49d2-41b3-925a-6818d05c3de7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logging helps track progress instead of messy print statements\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format=\"%(asctime)s | %(levelname)s | %(message)s\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f5ae83c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Parse RSS Feed Function\n",
    "def parse_rss_feed(feed_url):\n",
    "    feed = feedparser.parse(feed_url)\n",
    "    # Limit number of articles to avoid overload\n",
    "    return feed.entries[:MAX_ARTICLES_PER_FEED]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fbbeaae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scrape Single Article Function\n",
    "def scrape_article(article_url, fallback_data):\n",
    "    article = newspaper.Article(article_url)\n",
    "    # Download article HTML\n",
    "    article.download()\n",
    "    # Parse article content\n",
    "    article.parse()\n",
    "\n",
    "    return {\n",
    "        # Prefer newspaper extracted data, fallback to RSS data\n",
    "        \"title\": article.title or fallback_data.get(\"title\", \"\"),\n",
    "        \"authors\": \", \".join(article.authors) if article.authors else \"\",\n",
    "        \"publish_date\": article.publish_date or fallback_data.get(\"published\", \"\"),\n",
    "        \"content\": article.text.strip(),\n",
    "        \"source_url\": article_url,\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ac0eb5fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Main Scraping Function\n",
    "def scrape_news_from_feeds(feed_urls):\n",
    "    all_articles = []\n",
    "    seen_urls = set()\n",
    "\n",
    "    for feed_url in feed_urls:\n",
    "        entries = parse_rss_feed(feed_url)\n",
    "\n",
    "        for entry in entries:\n",
    "            url = entry.get(\"link\")\n",
    "            # Skip invalid or duplicate URLs\n",
    "            if not url or url in seen_urls:\n",
    "                continue\n",
    "\n",
    "            try:\n",
    "                article_data = scrape_article(url, entry)\n",
    "                # Skip very short or empty articles\n",
    "                if len(article_data[\"content\"]) < 200:\n",
    "                    continue\n",
    "\n",
    "                all_articles.append(article_data)\n",
    "                seen_urls.add(url)\n",
    "\n",
    "                logging.info(f\"Scraped: {article_data['title'][:60]}...\")\n",
    "                time.sleep(DELAY_BETWEEN_ARTICLES)\n",
    "\n",
    "            except Exception as e:\n",
    "                logging.warning(f\"Failed to scrape {url} | {e}\")\n",
    "\n",
    "    return all_articles\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "440f7886",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-12 21:39:02,406 | INFO | Scraped: Minneapolis immigration enforcement operation to 'conclude',...\n",
      "2026-02-12 21:39:03,068 | INFO | Scraped: 'Vast majority' of parents should be involved if children qu...\n",
      "2026-02-12 21:39:03,718 | INFO | Scraped: Trump case against BBC to go to trial in February 2027...\n",
      "2026-02-12 21:39:04,389 | INFO | Scraped: Jim Ratcliffe sorry language 'offended some' after immigrati...\n",
      "2026-02-12 21:39:05,054 | INFO | Scraped: Kim Ju Ae: North Korea leader Kim Jong Un chooses daughter a...\n",
      "2026-02-12 21:39:05,730 | INFO | Scraped: Robin Windsor: Strictly star took own life after mental heal...\n",
      "2026-02-12 21:39:06,455 | INFO | Scraped: Reeves says 'more to do' after sluggish GDP growth...\n",
      "2026-02-12 21:39:07,323 | INFO | Scraped: Alton Towers U-turns on plan to restrict disability pass for...\n",
      "2026-02-12 21:39:08,269 | INFO | Scraped: 2026 Winter Olympics: Why Vladyslav Heraskevych was banned f...\n",
      "2026-02-12 21:39:09,162 | INFO | Scraped: Team GB's Matt Weston leads skeleton standings after two run...\n",
      "2026-02-12 21:39:10,094 | INFO | Scraped: Winter Olympics: How Team GB can still win plenty of medals...\n",
      "2026-02-12 21:39:10,743 | INFO | Scraped: Dawson's Creek: The 90s teen drama that 'wore its heart on i...\n",
      "2026-02-12 21:39:11,460 | INFO | Scraped: What to know about bowel cancer and how to spot it...\n",
      "2026-02-12 21:39:12,387 | INFO | Scraped: Parents blame baby deaths on misssed chances at Sussex NHS t...\n",
      "2026-02-12 21:39:13,121 | INFO | Scraped: Cancer DNA blood test rolled out after Welsh trial...\n",
      "2026-02-12 21:39:13,815 | INFO | Scraped: The Dutch love four-day working weeks, but are they sustaina...\n",
      "2026-02-12 21:39:14,497 | INFO | Scraped: Four takeaways from Pam Bondi's fiery Epstein testimony...\n",
      "2026-02-12 21:39:15,222 | INFO | Scraped: Killer of 12-year-old schoolboy Leo Ross named...\n",
      "2026-02-12 21:39:15,887 | INFO | Scraped: Daily Mail owner's takeover of Telegraph to face probe...\n",
      "2026-02-12 21:39:16,727 | INFO | Scraped: UK weather: Snow and ice warnings issued after relentless ra...\n",
      "2026-02-12 21:39:17,389 | INFO | Scraped: Motorway collapses as deadly storms hit France, Portugal and...\n",
      "2026-02-12 21:39:18,079 | INFO | Scraped: Prince Harry thanks bereaved families taking on social media...\n",
      "2026-02-12 21:39:18,772 | INFO | Scraped: MPs fear data centre boom could derail Miliband's net zero p...\n",
      "2026-02-12 21:39:20,167 | INFO | Scraped: The BBC News app keeps you informed with live and breaking n...\n",
      "2026-02-12 21:39:20,765 | INFO | Scraped: Two More Problems For Keir Starmer?...\n",
      "2026-02-12 21:39:21,422 | INFO | Scraped: Has Jeff Bezos brought down the Washington Post?...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total articles scraped: 26\n",
      "Saved to: c:\\Users\\shukl\\OneDrive\\Desktop\\Data-Analytics-Portfolio\\Python\\Web-Scraping\\News-Scraping\\outputs\\news_articles.csv\n"
     ]
    }
   ],
   "source": [
    "#Run Scraper & Save Output\n",
    "\n",
    "articles = scrape_news_from_feeds(RSS_FEEDS)\n",
    "\n",
    "df = pd.DataFrame(articles)\n",
    "# Arrange columns for analytics friendliness\n",
    "df = df[[\"title\", \"authors\", \"publish_date\", \"content\", \"source_url\"]]\n",
    "\n",
    "df.to_csv(OUTPUT_FILE, index=False, encoding=\"utf-8\")\n",
    "\n",
    "print(f\"Total articles scraped: {len(df)}\")\n",
    "print(f\"Saved to: {OUTPUT_FILE}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
